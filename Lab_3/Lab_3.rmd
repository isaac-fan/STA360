---
title: "STA 360 Lab 3: The Beta-Binomial model"
author: "STA 360: Bayesian Inference and Modern Statistical Methods"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  pdf_document: default
  html_document: default
---

```{r setup, message=F, warning=F, echo=F}
#
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
#
ggplot2::theme_set(ggplot2::theme_bw())
knitr::opts_chunk$set(fig.align = 'center')
```

# Preliminaries

Please turn in a PDF of this Rmd file on Sakai by Friday, February 12th at 11:59 PM. Exercises 2 and 4 will be graded for completion.

# Repeated Binomial Trials

By this point, you are familiar with binomial data: If $Y \sim Binom(n,\theta)$, we assume the data are such that over $n$ trials with success probability $\theta$, we observe $y$ successes. Let us consider multiple binomial realizations. We have data on rat tumor development from Tarone (1982). Specifically, we have the number of incidences of endometrial stromal polyps in 71 different groups of female lab rats of type F344. We begin by loading in the data:

```{r}
tumors <- read.csv(file = url("http://www.stat.columbia.edu/~gelman/book/data/rats.asc"),
                     skip = 2, header = T, sep = " ")[,c(1,2)]
y <- tumors$y # number of successes
N <- tumors$N # binomial trials
n <- length(y) # sample size
```

Each row represents a group, or a draw from a binomial distribution. The $y$ variable denotes the number of succcesses and the $N$ variable denotes the total number of rats in that control group. For example the first group consists of $20$ rats, with $0$ of these $20$ having developed a tumor. $n$ is the number of groups.

If we assume that the probability of developing a tumor is the same across groups, then for each of the $i = 1,2,\ldots, n$ groups, we have $y_i \sim Binom(N_i, \theta)$. We have learned that the Beta distribution is conjugate for Binomial data. For now, we place a $Beta(1,1)$ prior on $\theta$, which corresponds to a uniform density on the interval $[0,1]$.

```{r}
plot(seq(0, 1, length.out = 1000), 
     dbeta(seq(0, 1, length.out = 1000), 1, 1),
     type = 'l', 
     xlab = expression(theta), ylab = "Density",
     main = "The Beta(1, 1) density")
```

Now suppose we wanted to draw values from the posterior.

***
### Exercise 0

Recall that if $Y \sim Binom(N, \theta)$ and $\theta \sim Beta(a,b)$, then $(\theta\mid Y)\sim Beta(a+y, b+n-y)$. Sample 1,000 observations from this posterior. Make a density plot of the observations.

```{r}
beta.values <- rbeta(n = 1000, shape1 = 1 + sum(y), shape2 = 1 + sum(N) - sum(y))

plot(density(beta.values), type = "l")
```


***

An alternative way to do this is to use `stan`. `stan` files consist of 3 parts:

* `data` that need to be input
* `parameters` that are to be estimated
* a `model` that describes the sampling model and the prior distributions

In the `Rmd` file, we supply the actual data and call file using the `stan()` function (example below). We can then extract outputs from the model that represent our posterior distribution(s) for further analysis. Let's take a look with some examples:

```{r pooled}
stan_dat <- list(n = n, N = N, y =y, a = 1, b = 1)
fit_pool <- stan('lab3_pool.stan', data = stan_dat, chains = 2, refresh = 0)
pool_output <- rstan::extract(fit_pool)
mean(pool_output$theta)
mean(beta.values)
```

***
### Exercise 1

Plot a density of the prior distribution, and plot a density of $\theta$ from the `rstan` object called `pool_output` on the same graph. Since we know the posterior distribution (see, for example, Exercise 3 on HW 1), do these distributions seem reasonable? How do they compare to each other?

```{r}
plot(density(pool_output$theta), type = 'l')
```

***

Alternatively, we may not have reason to believe that the probability of a rat developing a tumor should be the same across groups. Then we have the model $y_i \sim Binom(N_i, \theta_i)$ for $i = 1,2,\ldots,n$. If we had expert knowledge about the different groups of rats, we might place different priors on each of the $n$ $\theta_i$'s. However, for simplicity we choose to model the $\theta_i$ as i.i.d. $Beta(1,1)$.

```{r non-pooled}
stan_dat <- list(n = n, N = N, y =y, a = 1, b = 1)
fit_nopool <- stan('lab3_nopool.stan', data = stan_dat, chains = 2, refresh = 0)
nopool_output <- rstan::extract(fit_nopool)
apply(nopool_output$theta,2,mean)
```


```{r}
samples <- nopool_output[[1]]
dim(samples)
head(samples)
```

***
### Exercise 2

Visualize the posterior distributions of the $\theta_i$ with boxplots. In the plot, there should be one box and whiskers object for each $\theta_i$. 

What is actually being plotted here (i.e., you can describe this with a mathematical expression and/or in words)? What does each point represent?

```{r}
boxplot(nopool_output$theta)
```

Each boxplot is the distribution of thetas in each set of trials. 
***

# Sensitivity analysis

With the Beta-Binomial model, we know that the posterior is $\theta | Y \sim Beta(a + \sum y_i, b + \sum N_i- \sum y_i)$. Therefore, the posterior mean is $$E[\theta | Y] = \frac{a + \sum y_i}{a + b + \sum N_i}$$ We fit the above models with $a=1, b=1$, but it is good practice to perform an analysis to determine how sensitive the posterior is to the choice of prior. Considering the first model where we assumed the same success probability $\theta$ across groups, let us sample from the posterior distribution of $\theta$ over a range of $a$ and $b$ values. These parameter settings produce very different pictures of our prior beliefs about $\theta$:

```{r}
par(mfrow = c(4, 4))
par(mar=c(2,2,2,2))
for(a_val in c(1, 10, 25, 100)){
  for(b_val in rev(c(1, 10, 25, 100))){
    plot(seq(0, 1, length.out = 1000), 
     dbeta(seq(0, 1, length.out = 1000), a_val, b_val),
     type = 'l', 
     xlab = expression(theta), ylab = "Density",
     main = paste0("Beta(", a_val, ", ", b_val, ")"))
  }
}
```

To get samples from the posterior distribution of $\theta$ for each one of the prior distributions above, we run:

```{r sensitivity_analysis}
output_list <- list()
for(a_val in c(1, 10, 25, 100)){
  for(b_val in c(1, 10, 25, 100)){
    stan_dat <- list(n = n, N = N, y = y, a = a_val, b = b_val)
    fit_pool <- stan('lab3_pool.stan', data = stan_dat, chains = 2, refresh = 0)
    output_list[[paste0("a_", a_val, ":b_", b_val)]] <- rstan::extract(fit_pool)[["theta"]]
  }
}
```

We then compile the samples from the different prior specifications into a data.frame, which will help us visualize the results.

```{r}
output_list %>%
  plyr::ldply(function(theta){
    reshape2::melt(theta) %>%
      dplyr::mutate(post_mean = mean(theta))
  }, .id = "prior") %>%
  tidyr::separate("prior", into = c("a", "b"), sep = ":") %>%
  dplyr::mutate(a = as.numeric(gsub("._", "", a)),
                b = as.numeric(gsub("._", "", b))) %>%
  ggplot2::ggplot() +
  geom_density(aes(x = value)) +
  geom_vline(aes(xintercept = post_mean)) +
  facet_grid(a~factor(b, levels = rev(c(1, 10, 25, 100)))) +
  scale_colour_brewer(palette = "Set1") +
  labs(x = expression(theta), y = "Density")
```

In the plot above, increasing values of the parameter $a$ are displayed moving from top to bottom along the vertical direction. Decreasing values of the parameter $b$ are displayed moving from left to right along the horizontal direction. We can see that all of the posterior distributions look roughly normal with roughly equal variance. They are all fairly concentrated on values of $\theta$ within the range $[0.1, 0.2]$. 

Here is a further observation that is specific to the concept of sensitivity analysis: for fixed $a$, as $b$ increases the posterior mean shifts slightly towards lower values of $\theta$. But for fixed $b$, as $a$ increases the posterior mean shifts more dramatically towards higher values of $\theta$. We might say that the posterior mean of $\theta$ is more sensitive to our prior beliefs about $a$ than it is to our prior beliefs about $b$. Why might this be the case?

We can look at the formula for the posterior mean above to find an explicit answer. What might be a more intuitive explanation for the posterior's high sensitivity to the parameter $a$? 

***
### Exercise 3

Here are some questions to consider:

1. What observable quantity does the parameter $a$ represent about our prior beliefs with respect to these data? What does $b$ represent?
2. What do we actually observe in the rat tumor data with respect to these quantities?
3. How well do our different prior beliefs -- the ones represented by the different parameter settings above -- match up with the data?

***

### Exercise 4

Returning to the initial exploration where we considered a single $\theta$ versus allowing $\theta_i$ to vary across groups: You should have noticed that if we allow the groups to have different success probabilities, then our estimates $\hat{\theta}_i$ vary from 0.05 to 0.30. However when we assumed a single probability of success, we obtained $\hat{\theta}\approx$ 0.15. In this first approach and assuming the 71 groups are independent, we essentially have one large binomial trial: $Y^* = \sum y_i \sim Binom(\sum N_i, \theta)$. Applying ideas from the sensitivity analysis. Why might we have observed such a difference between the two approaches when using the prior $Beta(1,1)$ in both cases?

(a) Derive or state the maximum likelihood estimate (MLE) for the binomial model $y\mid\theta\sim\text{Binom}(n,\theta)$.

Approach 1:
$$
\widehat{\theta}^{ML} = sum(yi)/sum(Ni)
$$

Approach 2:
$$
\widehat{\theta}_i^{ML} = yi / ni
$$


(b) Compute the MLE estimates for both problems (i.e., when we have the same $\theta$ for each group and when we have a different $\theta$ for each group).
```{r MLE}
# approach 1
sum(y) / sum(N)

# approach 2
y/N
```

(c) State what the expectation is for the prior beta distribution $\theta\sim\text{Beta}(a,b)$:

$$
\mathsf{E}[\theta] = a/(a+b)
$$

(d) Recall that if $Y \sim Binom(N, \theta)$ and $\theta \sim Beta(a,b)$, then $(\theta\mid Y)\sim Beta(a+y, b+n-y)$. State what the expectation is for this posterior distribution, and show that you can write it as a weighted average of the MLE $\widehat{\theta}^{ML}$ and the prior expectation $\mathsf{E}[\theta]$.

$$
\mathsf{E}[\theta\mid Y=y] = \frac{a + y} {b+a+n} = \frac{(a+b)}{(b+a+n)} *\frac{a}{(a+b)} +  \frac{n}{b+a+n} *\frac{y}{n}
$$

(e) How does this help explain the difference between our estimates of $\theta$ in our two approaches?

Looking at the weighted average, the more samples there are, the greater the weight given to the MLE is. Thus, our pooled estimate will place a greater weight on the observations and less weight on the prior. Our nonpooled theta estimates will give a greater weight to the prior.

***

